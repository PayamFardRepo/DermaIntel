{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Balanced Skin Cancer Classifier Training\n",
    "\n",
    "This notebook trains a ResNet50 model for skin cancer classification with:\n",
    "- Class-weighted loss function\n",
    "- Focal Loss for hard examples\n",
    "- Aggressive data augmentation for minority class\n",
    "- Oversampling with WeightedRandomSampler\n",
    "- Threshold optimization for clinical use\n",
    "- **Automatic checkpointing** (saves after every epoch, resumes if interrupted)\n",
    "\n",
    "Target: 90% sensitivity for malignant detection"
   ],
   "metadata": {
    "id": "intro"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Setup & Configuration"
   ],
   "metadata": {
    "id": "setup_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected! Training will be very slow.\")\n",
    "    print(\"Go to Runtime > Change runtime type > Hardware accelerator > GPU\")"
   ],
   "metadata": {
    "id": "check_gpu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Mount Google Drive for data and checkpoints\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create directories for checkpoints\n",
    "import os\n",
    "CHECKPOINT_DIR = '/content/drive/MyDrive/skin_classifier_checkpoints'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "print(f\"Checkpoints will be saved to: {CHECKPOINT_DIR}\")"
   ],
   "metadata": {
    "id": "mount_drive"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ===========================================\n# CONFIGURATION - Ready to run!\n# ===========================================\n# Your data should be uploaded to Google Drive with this structure:\n#   My Drive/\n#     isic_organized/\n#       benign/\n#         *.jpg images\n#       malignant/\n#         *.jpg images\n#\n# To upload: Drag your local backend/data/isic/organized folder\n# to Google Drive and rename it to \"isic_organized\"\n# ===========================================\n\nfrom pathlib import Path\n\nCONFIG = {\n    # Data path - points to your ISIC organized folder in Google Drive\n    'data_dir': '/content/drive/MyDrive/isic_organized',\n\n    # Training parameters\n    'epochs': 20,\n    'batch_size': 32,\n    'learning_rate': 1e-4,\n\n    # Loss function\n    'use_focal_loss': True,\n    'focal_gamma': 2.0,\n\n    # Target sensitivity for cancer detection\n    'target_sensitivity': 0.90,  # 90%\n\n    # Output directory (in Google Drive for persistence)\n    'output_dir': CHECKPOINT_DIR,\n}\n\nprint(\"Configuration:\")\nfor k, v in CONFIG.items():\n    print(f\"  {k}: {v}\")\n\n# Verify data directory exists\nif os.path.exists(CONFIG['data_dir']):\n    benign_count = len(list(Path(CONFIG['data_dir']).glob('benign/*.jpg')))\n    malignant_count = len(list(Path(CONFIG['data_dir']).glob('malignant/*.jpg')))\n    print(f\"\\nData found!\")\n    print(f\"  Benign images: {benign_count}\")\n    print(f\"  Malignant images: {malignant_count}\")\nelse:\n    print(f\"\\nWARNING: Data directory not found at {CONFIG['data_dir']}\")\n    print(\"Please upload your 'organized' folder from backend/data/isic/organized\")\n    print(\"to Google Drive and rename it to 'isic_organized'\")",
   "metadata": {
    "id": "config"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Imports & Dependencies"
   ],
   "metadata": {
    "id": "imports_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from typing import Tuple, Dict, List, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    precision_recall_curve, roc_curve, f1_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"All imports successful!\")"
   ],
   "metadata": {
    "id": "imports"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Focal Loss Implementation"
   ],
   "metadata": {
    "id": "focal_loss_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal Loss for handling class imbalance.\n",
    "    \n",
    "    Focuses training on hard examples by down-weighting easy examples.\n",
    "    Originally proposed for object detection (RetinaNet paper).\n",
    "    \n",
    "    FL(p_t) = -alpha_t * (1 - p_t)^gamma * log(p_t)\n",
    "    \n",
    "    Args:\n",
    "        alpha: Class balancing weight (higher for minority class)\n",
    "        gamma: Focusing parameter (higher = more focus on hard examples)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: Optional[torch.Tensor] = None, gamma: float = 2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        \n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "        \n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha[targets]\n",
    "            focal_loss = alpha_t * focal_loss\n",
    "        \n",
    "        return focal_loss.mean()"
   ],
   "metadata": {
    "id": "focal_loss"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Data Augmentation"
   ],
   "metadata": {
    "id": "augmentation_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_train_transforms(is_malignant: bool = False) -> transforms.Compose:\n",
    "    \"\"\"\n",
    "    Get training transforms with extra augmentation for malignant samples.\n",
    "    \n",
    "    Malignant samples get more aggressive augmentation to increase diversity.\n",
    "    \"\"\"\n",
    "    base_transforms = [\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=30),\n",
    "    ]\n",
    "    \n",
    "    if is_malignant:\n",
    "        # Extra augmentation for minority class\n",
    "        base_transforms.extend([\n",
    "            transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "            transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
    "            transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "        ])\n",
    "    else:\n",
    "        base_transforms.extend([\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "        ])\n",
    "    \n",
    "    base_transforms.extend([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        transforms.RandomErasing(p=0.1),  # Cutout augmentation\n",
    "    ])\n",
    "    \n",
    "    return transforms.Compose(base_transforms)\n",
    "\n",
    "\n",
    "def get_val_transforms() -> transforms.Compose:\n",
    "    \"\"\"Validation/test transforms - no augmentation.\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])"
   ],
   "metadata": {
    "id": "augmentation"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Dataset Class"
   ],
   "metadata": {
    "id": "dataset_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class BalancedSkinDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Skin lesion dataset with class-aware augmentation.\n",
    "    \n",
    "    Malignant samples get more aggressive augmentation to increase diversity.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Map various diagnosis labels to binary\n",
    "    MALIGNANT_LABELS = {'mel', 'melanoma', 'bcc', 'basal cell carcinoma', 'akiec',\n",
    "                        'actinic keratosis', 'squamous cell carcinoma', 'scc', 'malignant'}\n",
    "    BENIGN_LABELS = {'nv', 'nevus', 'bkl', 'benign keratosis', 'df', 'dermatofibroma',\n",
    "                     'vasc', 'vascular', 'benign'}\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        image_paths: List[str],\n",
    "        labels: List[int],\n",
    "        transform: Optional[transforms.Compose] = None,\n",
    "        malignant_transform: Optional[transforms.Compose] = None,\n",
    "        is_training: bool = True\n",
    "    ):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.malignant_transform = malignant_transform\n",
    "        self.is_training = is_training\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Use different transforms for malignant during training\n",
    "        if self.is_training and label == 1 and self.malignant_transform:\n",
    "            image = self.malignant_transform(image)\n",
    "        elif self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ],
   "metadata": {
    "id": "dataset"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Model Architecture"
   ],
   "metadata": {
    "id": "model_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def create_model(num_classes: int = 2, pretrained: bool = True, dropout: float = 0.3) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Create a ResNet50 model with dropout for uncertainty estimation.\n",
    "    \n",
    "    Uses Monte Carlo Dropout for uncertainty quantification during inference.\n",
    "    \"\"\"\n",
    "    model = models.resnet50(weights='IMAGENET1K_V2' if pretrained else None)\n",
    "    \n",
    "    # Add dropout before final layer\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(p=dropout),\n",
    "        nn.Linear(num_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=dropout),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "id": "model"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Training Utilities"
   ],
   "metadata": {
    "id": "utils_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_class_weights(labels: List[int], device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute class weights inversely proportional to class frequency.\n",
    "    \n",
    "    For medical applications, we weight malignant class higher because\n",
    "    missing cancer is much worse than a false positive.\n",
    "    \"\"\"\n",
    "    counter = Counter(labels)\n",
    "    total = len(labels)\n",
    "    \n",
    "    # Inverse frequency weighting\n",
    "    weights = []\n",
    "    for i in range(len(counter)):\n",
    "        # Add extra weight to malignant class (clinical importance)\n",
    "        if i == 1:  # Malignant class\n",
    "            weight = (total / counter[i]) * 2.0  # 2x extra weight for malignant\n",
    "        else:\n",
    "            weight = total / counter[i]\n",
    "        weights.append(weight)\n",
    "    \n",
    "    # Normalize weights\n",
    "    weights = torch.tensor(weights, dtype=torch.float32)\n",
    "    weights = weights / weights.sum() * len(weights)\n",
    "    \n",
    "    print(f\"\\nClass weights: {weights.tolist()}\")\n",
    "    print(f\"  Benign (0): {weights[0]:.3f}\")\n",
    "    print(f\"  Malignant (1): {weights[1]:.3f}\")\n",
    "    \n",
    "    return weights.to(device)\n",
    "\n",
    "\n",
    "def create_weighted_sampler(labels: List[int]) -> WeightedRandomSampler:\n",
    "    \"\"\"\n",
    "    Create a weighted sampler that oversamples minority class.\n",
    "    \n",
    "    This ensures each batch has roughly equal representation of both classes.\n",
    "    \"\"\"\n",
    "    counter = Counter(labels)\n",
    "    class_weights = {cls: 1.0 / count for cls, count in counter.items()}\n",
    "    \n",
    "    # Assign weight to each sample based on its class\n",
    "    sample_weights = [class_weights[label] for label in labels]\n",
    "    \n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(labels),\n",
    "        replacement=True\n",
    "    )\n",
    "    \n",
    "    return sampler"
   ],
   "metadata": {
    "id": "class_weights"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train_epoch(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    epoch: int\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Train]\")\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{running_loss/len(pbar):.4f}',\n",
    "            'acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    return running_loss / len(dataloader), 100. * correct / total"
   ],
   "metadata": {
    "id": "train_epoch"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device,\n",
    "    threshold: float = 0.5\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluate model with comprehensive metrics.\n",
    "    \n",
    "    For medical applications, we focus on:\n",
    "    - Sensitivity (Recall): % of actual cancers correctly identified\n",
    "    - Specificity: % of benign correctly identified\n",
    "    - NPV: If we say benign, how confident are we?\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())  # Probability of malignant\n",
    "            \n",
    "            # Use threshold for predictions\n",
    "            preds = (probs[:, 1] >= threshold).long()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "    \n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    # Compute metrics\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0  # Recall for malignant\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0  # Recall for benign\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    npv = tn / (tn + fn) if (tn + fn) > 0 else 0  # Negative predictive value\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    f1 = 2 * precision * sensitivity / (precision + sensitivity) if (precision + sensitivity) > 0 else 0\n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_probs)\n",
    "    except:\n",
    "        auc = 0.0\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': running_loss / len(dataloader),\n",
    "        'accuracy': accuracy * 100,\n",
    "        'sensitivity': sensitivity * 100,  # Most important for cancer detection\n",
    "        'specificity': specificity * 100,\n",
    "        'precision': precision * 100,\n",
    "        'npv': npv * 100,\n",
    "        'f1': f1 * 100,\n",
    "        'auc': auc * 100,\n",
    "        'confusion_matrix': cm.tolist(),\n",
    "        'threshold': threshold,\n",
    "        'tp': int(tp),\n",
    "        'tn': int(tn),\n",
    "        'fp': int(fp),\n",
    "        'fn': int(fn),\n",
    "    }\n",
    "    \n",
    "    return metrics, all_labels, all_probs"
   ],
   "metadata": {
    "id": "evaluate"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def find_optimal_threshold(labels: np.ndarray, probs: np.ndarray, target_sensitivity: float = 0.95) -> float:\n",
    "    \"\"\"\n",
    "    Find the optimal threshold to achieve target sensitivity.\n",
    "    \n",
    "    For cancer screening, we want HIGH sensitivity (catch most cancers)\n",
    "    even at the cost of more false positives.\n",
    "    \"\"\"\n",
    "    thresholds = np.arange(0.05, 0.95, 0.01)\n",
    "    best_threshold = 0.5\n",
    "    best_f1 = 0\n",
    "    \n",
    "    print(f\"\\nFinding optimal threshold (target sensitivity: {target_sensitivity*100:.0f}%):\")\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        preds = (probs >= thresh).astype(int)\n",
    "        cm = confusion_matrix(labels, preds)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        \n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        f1 = 2 * precision * sensitivity / (precision + sensitivity) if (precision + sensitivity) > 0 else 0\n",
    "        \n",
    "        # Find threshold that achieves target sensitivity with best F1\n",
    "        if sensitivity >= target_sensitivity and f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = thresh\n",
    "            print(f\"  Threshold {thresh:.2f}: Sensitivity={sensitivity*100:.1f}%, Precision={precision*100:.1f}%, F1={f1*100:.1f}%\")\n",
    "    \n",
    "    return best_threshold"
   ],
   "metadata": {
    "id": "find_threshold"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_training_history(history: Dict, save_path: str):\n",
    "    \"\"\"Plot training curves and save.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(history['train_loss'], label='Train')\n",
    "    axes[0, 0].plot(history['val_loss'], label='Validation')\n",
    "    axes[0, 0].set_title('Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 1].plot(history['train_acc'], label='Train')\n",
    "    axes[0, 1].plot(history['val_acc'], label='Validation')\n",
    "    axes[0, 1].set_title('Accuracy')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Sensitivity (most important)\n",
    "    axes[1, 0].plot(history['val_sensitivity'], label='Sensitivity (Recall)', color='red')\n",
    "    axes[1, 0].plot(history['val_specificity'], label='Specificity', color='blue')\n",
    "    axes[1, 0].axhline(y=90, color='green', linestyle='--', label='90% target')\n",
    "    axes[1, 0].set_title('Sensitivity vs Specificity')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylim([0, 100])\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # AUC\n",
    "    axes[1, 1].plot(history['val_auc'], label='AUC-ROC', color='purple')\n",
    "    axes[1, 1].set_title('AUC-ROC')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylim([50, 100])\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    print(f\"Training plots saved to {save_path}\")"
   ],
   "metadata": {
    "id": "plot_history"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. Data Loading"
   ],
   "metadata": {
    "id": "data_loading_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def load_isic_data(data_dir: str) -> Tuple[List[str], List[int]]:\n",
    "    \"\"\"\n",
    "    Load ISIC dataset with binary labels.\n",
    "    \n",
    "    Expects either:\n",
    "    - Organized folders: data_dir/benign/*.jpg, data_dir/malignant/*.jpg\n",
    "    - Or CSV metadata with image paths and diagnoses\n",
    "    \"\"\"\n",
    "    data_path = Path(data_dir)\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    # Check for organized folder structure\n",
    "    benign_dir = data_path / \"benign\"\n",
    "    malignant_dir = data_path / \"malignant\"\n",
    "    \n",
    "    if benign_dir.exists() and malignant_dir.exists():\n",
    "        print(\"Loading from organized folders...\")\n",
    "        for img in benign_dir.glob(\"*.jpg\"):\n",
    "            image_paths.append(str(img))\n",
    "            labels.append(0)\n",
    "        for img in benign_dir.glob(\"*.png\"):\n",
    "            image_paths.append(str(img))\n",
    "            labels.append(0)\n",
    "        for img in malignant_dir.glob(\"*.jpg\"):\n",
    "            image_paths.append(str(img))\n",
    "            labels.append(1)\n",
    "        for img in malignant_dir.glob(\"*.png\"):\n",
    "            image_paths.append(str(img))\n",
    "            labels.append(1)\n",
    "    else:\n",
    "        # Look for CSV metadata\n",
    "        csv_files = list(data_path.glob(\"*.csv\"))\n",
    "        if csv_files:\n",
    "            print(f\"Loading from CSV: {csv_files[0]}\")\n",
    "            df = pd.read_csv(csv_files[0])\n",
    "            \n",
    "            # Try different column names\n",
    "            img_col = None\n",
    "            label_col = None\n",
    "            for col in df.columns:\n",
    "                if 'image' in col.lower() or 'path' in col.lower() or 'file' in col.lower():\n",
    "                    img_col = col\n",
    "                if 'diagnosis' in col.lower() or 'label' in col.lower() or 'target' in col.lower():\n",
    "                    label_col = col\n",
    "            \n",
    "            if img_col and label_col:\n",
    "                for _, row in df.iterrows():\n",
    "                    img_path = data_path / row[img_col]\n",
    "                    if not img_path.exists():\n",
    "                        img_path = data_path / \"images\" / row[img_col]\n",
    "                    \n",
    "                    if img_path.exists():\n",
    "                        image_paths.append(str(img_path))\n",
    "                        \n",
    "                        # Convert label to binary\n",
    "                        label_str = str(row[label_col]).lower()\n",
    "                        if label_str in BalancedSkinDataset.MALIGNANT_LABELS or label_str == '1':\n",
    "                            labels.append(1)\n",
    "                        else:\n",
    "                            labels.append(0)\n",
    "    \n",
    "    print(f\"Loaded {len(image_paths)} images\")\n",
    "    print(f\"  Benign: {labels.count(0)}\")\n",
    "    print(f\"  Malignant: {labels.count(1)}\")\n",
    "    print(f\"  Imbalance ratio: {labels.count(0) / max(labels.count(1), 1):.1f}:1\")\n",
    "    \n",
    "    return image_paths, labels"
   ],
   "metadata": {
    "id": "load_data"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "print(\"Loading ISIC data...\")\n",
    "image_paths, labels = load_isic_data(CONFIG['data_dir'])\n",
    "\n",
    "if len(image_paths) == 0:\n",
    "    raise ValueError(f\"ERROR: No images found in {CONFIG['data_dir']}. Please check the path.\")"
   ],
   "metadata": {
    "id": "load_data_run"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Split data with stratification\n",
    "train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.3, stratify=labels, random_state=42\n",
    ")\n",
    "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
    "    temp_paths, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"  Train: {len(train_paths)} (Benign: {train_labels.count(0)}, Malignant: {train_labels.count(1)})\")\n",
    "print(f\"  Val: {len(val_paths)} (Benign: {val_labels.count(0)}, Malignant: {val_labels.count(1)})\")\n",
    "print(f\"  Test: {len(test_paths)} (Benign: {test_labels.count(0)}, Malignant: {test_labels.count(1)})\")"
   ],
   "metadata": {
    "id": "split_data"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9. Create Datasets & DataLoaders"
   ],
   "metadata": {
    "id": "dataloaders_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Create datasets with class-aware augmentation\n",
    "train_dataset = BalancedSkinDataset(\n",
    "    train_paths, train_labels,\n",
    "    transform=get_train_transforms(is_malignant=False),\n",
    "    malignant_transform=get_train_transforms(is_malignant=True),\n",
    "    is_training=True\n",
    ")\n",
    "val_dataset = BalancedSkinDataset(\n",
    "    val_paths, val_labels,\n",
    "    transform=get_val_transforms(),\n",
    "    is_training=False\n",
    ")\n",
    "test_dataset = BalancedSkinDataset(\n",
    "    test_paths, test_labels,\n",
    "    transform=get_val_transforms(),\n",
    "    is_training=False\n",
    ")\n",
    "\n",
    "# Create weighted sampler for training\n",
    "train_sampler = create_weighted_sampler(train_labels)\n",
    "\n",
    "# Note: Use num_workers=2 for Colab (not 4)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=CONFIG['batch_size'],\n",
    "    sampler=train_sampler, num_workers=2, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False, num_workers=2, pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False, num_workers=2, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoaders created:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")"
   ],
   "metadata": {
    "id": "create_dataloaders"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 10. Initialize Model & Training Components"
   ],
   "metadata": {
    "id": "init_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create model\n",
    "model = create_model(num_classes=2, pretrained=True, dropout=0.3)\n",
    "model = model.to(device)\n",
    "print(f\"Model created: ResNet50 with custom head\")\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weights(train_labels, device)\n",
    "\n",
    "# Loss function\n",
    "if CONFIG['use_focal_loss']:\n",
    "    print(f\"\\nUsing Focal Loss with gamma={CONFIG['focal_gamma']}\")\n",
    "    criterion = FocalLoss(alpha=class_weights, gamma=CONFIG['focal_gamma'])\n",
    "else:\n",
    "    print(\"\\nUsing Weighted Cross Entropy Loss\")\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Optimizer with weight decay\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=0.01)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG['epochs'])"
   ],
   "metadata": {
    "id": "init_model"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 11. Training Loop with Checkpointing"
   ],
   "metadata": {
    "id": "training_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [],\n",
    "    'val_loss': [], 'val_acc': [],\n",
    "    'val_sensitivity': [], 'val_specificity': [],\n",
    "    'val_auc': [], 'val_f1': []\n",
    "}\n",
    "\n",
    "best_sensitivity = 0\n",
    "best_f1 = 0\n",
    "best_model_path = None\n",
    "start_epoch = 0\n",
    "\n",
    "output_dir = Path(CONFIG['output_dir'])\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ============================================\n",
    "# CHECKPOINT RESUME - Check for existing checkpoint\n",
    "# ============================================\n",
    "checkpoint_path = output_dir / \"latest_checkpoint.pth\"\n",
    "if checkpoint_path.exists():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"RESUMING FROM CHECKPOINT\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Found existing checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_sensitivity = checkpoint.get('best_sensitivity', 0)\n",
    "    best_f1 = checkpoint.get('best_f1', 0)\n",
    "    history = checkpoint.get('history', history)\n",
    "    \n",
    "    print(f\"Resuming from epoch {start_epoch + 1}/{CONFIG['epochs']}\")\n",
    "    print(f\"Best sensitivity so far: {best_sensitivity:.2f}%\")\n",
    "    print(f\"Best F1 so far: {best_f1:.2f}%\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "else:\n",
    "    print(\"\\nNo checkpoint found. Starting fresh training.\")"
   ],
   "metadata": {
    "id": "checkpoint_resume"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING WITH CLASS BALANCING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Target: {CONFIG['target_sensitivity']*100:.0f}% sensitivity for malignant detection\")\n",
    "print(f\"Starting from epoch: {start_epoch + 1}\")\n",
    "print(f\"Total epochs: {CONFIG['epochs']}\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for epoch in range(start_epoch, CONFIG['epochs']):\n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "    \n",
    "    # Validate\n",
    "    val_metrics, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Record history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_metrics['loss'])\n",
    "    history['val_acc'].append(val_metrics['accuracy'])\n",
    "    history['val_sensitivity'].append(val_metrics['sensitivity'])\n",
    "    history['val_specificity'].append(val_metrics['specificity'])\n",
    "    history['val_auc'].append(val_metrics['auc'])\n",
    "    history['val_f1'].append(val_metrics['f1'])\n",
    "    \n",
    "    # Print epoch results\n",
    "    print(f\"\\nEpoch {epoch+1}/{CONFIG['epochs']}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Val Loss: {val_metrics['loss']:.4f}, Val Acc: {val_metrics['accuracy']:.2f}%\")\n",
    "    print(f\"  Sensitivity: {val_metrics['sensitivity']:.2f}% | Specificity: {val_metrics['specificity']:.2f}%\")\n",
    "    print(f\"  Precision: {val_metrics['precision']:.2f}% | F1: {val_metrics['f1']:.2f}% | AUC: {val_metrics['auc']:.2f}%\")\n",
    "    print(f\"  Confusion Matrix: TP={val_metrics['tp']}, TN={val_metrics['tn']}, FP={val_metrics['fp']}, FN={val_metrics['fn']}\")\n",
    "    \n",
    "    # Save best model based on sensitivity (most important for medical)\n",
    "    # But also consider F1 to avoid too many false positives\n",
    "    if val_metrics['sensitivity'] >= CONFIG['target_sensitivity'] * 100 and val_metrics['f1'] > best_f1:\n",
    "        best_f1 = val_metrics['f1']\n",
    "        best_sensitivity = val_metrics['sensitivity']\n",
    "        best_model_path = output_dir / \"best_balanced_model.pth\"\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'metrics': val_metrics,\n",
    "            'class_weights': class_weights.cpu().numpy().tolist(),\n",
    "        }, best_model_path)\n",
    "        print(f\"  New best model saved! (Sensitivity: {best_sensitivity:.2f}%, F1: {best_f1:.2f}%)\")\n",
    "    elif val_metrics['sensitivity'] > best_sensitivity:\n",
    "        best_sensitivity = val_metrics['sensitivity']\n",
    "        best_model_path = output_dir / \"best_balanced_model.pth\"\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'metrics': val_metrics,\n",
    "            'class_weights': class_weights.cpu().numpy().tolist(),\n",
    "        }, best_model_path)\n",
    "        print(f\"  New best sensitivity! (Sensitivity: {best_sensitivity:.2f}%)\")\n",
    "    \n",
    "    # ============================================\n",
    "    # SAVE CHECKPOINT AFTER EVERY EPOCH\n",
    "    # ============================================\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'best_sensitivity': best_sensitivity,\n",
    "        'best_f1': best_f1,\n",
    "        'history': history,\n",
    "        'metrics': val_metrics,\n",
    "    }, output_dir / \"latest_checkpoint.pth\")\n",
    "    print(f\"  Checkpoint saved (epoch {epoch+1})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)"
   ],
   "metadata": {
    "id": "training_loop"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 12. Final Evaluation"
   ],
   "metadata": {
    "id": "eval_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL EVALUATION ON TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load best model\n",
    "if best_model_path and best_model_path.exists():\n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "\n",
    "# Evaluate with default threshold\n",
    "test_metrics, test_labels_arr, test_probs = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"\\nTest Results (threshold=0.5):\")\n",
    "print(f\"  Accuracy: {test_metrics['accuracy']:.2f}%\")\n",
    "print(f\"  Sensitivity (Recall): {test_metrics['sensitivity']:.2f}%\")\n",
    "print(f\"  Specificity: {test_metrics['specificity']:.2f}%\")\n",
    "print(f\"  Precision: {test_metrics['precision']:.2f}%\")\n",
    "print(f\"  F1 Score: {test_metrics['f1']:.2f}%\")\n",
    "print(f\"  AUC-ROC: {test_metrics['auc']:.2f}%\")\n",
    "print(f\"  NPV: {test_metrics['npv']:.2f}%\")"
   ],
   "metadata": {
    "id": "final_eval"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Find optimal threshold for target sensitivity\n",
    "optimal_threshold = find_optimal_threshold(test_labels_arr, test_probs, CONFIG['target_sensitivity'])\n",
    "\n",
    "# Re-evaluate with optimal threshold\n",
    "test_metrics_opt, _, _ = evaluate(model, test_loader, criterion, device, threshold=optimal_threshold)\n",
    "\n",
    "print(f\"\\nTest Results (optimal threshold={optimal_threshold:.2f}):\")\n",
    "print(f\"  Accuracy: {test_metrics_opt['accuracy']:.2f}%\")\n",
    "print(f\"  Sensitivity (Recall): {test_metrics_opt['sensitivity']:.2f}%\")\n",
    "print(f\"  Specificity: {test_metrics_opt['specificity']:.2f}%\")\n",
    "print(f\"  Precision: {test_metrics_opt['precision']:.2f}%\")\n",
    "print(f\"  F1 Score: {test_metrics_opt['f1']:.2f}%\")"
   ],
   "metadata": {
    "id": "optimal_threshold"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 13. Save Results & Plot Training History"
   ],
   "metadata": {
    "id": "save_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Save results\n",
    "results = {\n",
    "    'model': 'resnet50_balanced',\n",
    "    'training_config': CONFIG,\n",
    "    'class_distribution': {\n",
    "        'train': {'benign': train_labels.count(0), 'malignant': train_labels.count(1)},\n",
    "        'val': {'benign': val_labels.count(0), 'malignant': val_labels.count(1)},\n",
    "        'test': {'benign': test_labels.count(0), 'malignant': test_labels.count(1)},\n",
    "    },\n",
    "    'test_metrics_default_threshold': test_metrics,\n",
    "    'test_metrics_optimal_threshold': test_metrics_opt,\n",
    "    'optimal_threshold': optimal_threshold,\n",
    "    'training_history': history,\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "}\n",
    "\n",
    "results_path = output_dir / \"training_results.json\"\n",
    "with open(results_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(f\"Results saved to: {results_path}\")"
   ],
   "metadata": {
    "id": "save_results"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot training history\n",
    "plot_training_history(history, str(output_dir / \"training_curves.png\"))"
   ],
   "metadata": {
    "id": "plot_results"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best model saved to: {best_model_path}\")\n",
    "print(f\"Results saved to: {output_dir / 'training_results.json'}\")\n",
    "print(f\"Training plots saved to: {output_dir / 'training_curves.png'}\")\n",
    "print(f\"\\nKey Achievement:\")\n",
    "print(f\"  Sensitivity: {test_metrics_opt['sensitivity']:.1f}% (detecting {test_metrics_opt['sensitivity']:.0f}% of cancers)\")\n",
    "print(f\"  With {test_metrics_opt['specificity']:.1f}% specificity\")\n",
    "print(f\"\\nAll files saved to Google Drive at:\")\n",
    "print(f\"  {output_dir}\")"
   ],
   "metadata": {
    "id": "summary"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 14. Download Model (Optional)"
   ],
   "metadata": {
    "id": "download_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Download the best model to your local machine\n",
    "from google.colab import files\n",
    "\n",
    "if best_model_path and best_model_path.exists():\n",
    "    print(\"Downloading best model...\")\n",
    "    files.download(str(best_model_path))\n",
    "else:\n",
    "    print(\"No best model found to download.\")"
   ],
   "metadata": {
    "id": "download_model"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}