{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# DermAI Pro - Balanced Skin Cancer Classifier Training\n\nThis notebook trains a skin lesion classifier with **balanced class weights** to improve malignant detection.\n\n## Problem Being Solved\n- Original model: 97% accuracy but only **30% precision, 41% recall for malignant**\n- This is due to severe class imbalance (55:1 ratio)\n- Goal: Achieve **90%+ sensitivity** for cancer detection\n\n## Techniques Used\n1. Class-weighted loss (malignant weighted 2x higher)\n2. Focal Loss for hard examples\n3. Weighted sampling (balanced batches)\n4. Aggressive augmentation for minority class\n5. Threshold optimization for clinical use\n\n## Resume Support\nThis notebook **automatically saves checkpoints** after every epoch. If disconnected:\n1. Re-run cells 2, 3, 4 (GPU, deps, mount Drive)\n2. Run cell 8 to verify data\n3. Run cells 9-20 to setup model\n4. Run cell 21 (training) - it will **automatically resume** from where it left off!\n\n## Quick Start\nRun cells: **2 → 3 → 4 → 8 → 9 → 10 → 11 → 12 → 13 → 14 → 15 → 16 → 17 → 18 → 19 → 20 → 21**\n\nSkip cells 5, 6, 7 (download steps - you already have data)\n\n---\n**Training: 8 epochs, ~3-4 hours per epoch from Google Drive**",
   "metadata": {
    "id": "header"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Setup Environment"
   ],
   "metadata": {
    "id": "setup-header"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected! Go to Runtime > Change runtime type > GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Install dependencies\n",
    "!pip install -q scikit-learn matplotlib tqdm pillow"
   ],
   "metadata": {
    "id": "install-deps"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Mount Google Drive to save/load data and models\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create working directory\n",
    "import os\n",
    "WORK_DIR = '/content/drive/MyDrive/DermAI_Training'\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "os.makedirs(f'{WORK_DIR}/checkpoints', exist_ok=True)\n",
    "print(f\"Working directory: {WORK_DIR}\")"
   ],
   "metadata": {
    "id": "mount-drive"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Download ISIC 2020 Dataset\n",
    "\n",
    "We'll download a subset of the ISIC 2020 dataset optimized for balanced training."
   ],
   "metadata": {
    "id": "data-header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Option A: Download from Kaggle (recommended - faster)\n",
    "# First, upload your kaggle.json API key\n",
    "\n",
    "# Uncomment and run if using Kaggle:\n",
    "# from google.colab import files\n",
    "# files.upload()  # Upload kaggle.json\n",
    "# !mkdir -p ~/.kaggle && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
    "# !kaggle datasets download -d nroman/melanoma-external-malignant-256\n",
    "# !unzip -q melanoma-external-malignant-256.zip -d /content/data"
   ],
   "metadata": {
    "id": "kaggle-download"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Option B: Download ISIC 2020 directly (smaller balanced subset)\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path('/content/data/isic')\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download HAM10000 dataset (balanced, ~10K images)\n",
    "print(\"Downloading HAM10000 dataset...\")\n",
    "!pip install -q kaggle\n",
    "\n",
    "# Alternative: Use the ISIC API or pre-prepared dataset\n",
    "print(\"\\nFor full ISIC 2020 dataset, please:\")\n",
    "print(\"1. Go to https://www.kaggle.com/datasets/nroman/melanoma-external-malignant-256\")\n",
    "print(\"2. Download and upload to Google Drive\")\n",
    "print(\"3. Update DATA_DIR path below\")"
   ],
   "metadata": {
    "id": "direct-download"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Check if data exists on Google Drive\nfrom pathlib import Path\nDATA_DIR = Path('/content/drive/MyDrive/DermAI_Training/organized')\n\nif DATA_DIR.exists():\n    benign_count = len(list((DATA_DIR / 'benign').glob('*.jpg')))\n    malignant_count = len(list((DATA_DIR / 'malignant').glob('*.jpg')))\n    print(f\"Found data on Google Drive:\")\n    print(f\"  Benign: {benign_count}\")\n    print(f\"  Malignant: {malignant_count}\")\n    print(f\"  Imbalance ratio: {benign_count/max(malignant_count,1):.1f}:1\")\n    print()\n    print(\"Next: Run the cell below to copy data locally for faster training\")\nelse:\n    print(f\"Data not found at {DATA_DIR}\")\n    print(\"Please upload your organized ISIC data to Google Drive\")",
   "metadata": {
    "id": "check-data"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Training Code"
   ],
   "metadata": {
    "id": "training-header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from typing import Tuple, Dict, List, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ],
   "metadata": {
    "id": "imports"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Focal Loss - better for imbalanced datasets\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha[targets]\n",
    "            focal_loss = alpha_t * focal_loss\n",
    "        return focal_loss.mean()"
   ],
   "metadata": {
    "id": "focal-loss"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Data augmentation\n",
    "def get_train_transforms(is_malignant=False):\n",
    "    base = [\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.RandomVerticalFlip(0.5),\n",
    "        transforms.RandomRotation(30),\n",
    "    ]\n",
    "    if is_malignant:\n",
    "        base.extend([\n",
    "            transforms.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "            transforms.ColorJitter(0.3, 0.3, 0.3, 0.1),\n",
    "            transforms.RandomPerspective(0.2, p=0.5),\n",
    "            transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "        ])\n",
    "    else:\n",
    "        base.append(transforms.ColorJitter(0.2, 0.2, 0.2, 0.05))\n",
    "    base.extend([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        transforms.RandomErasing(p=0.1),\n",
    "    ])\n",
    "    return transforms.Compose(base)\n",
    "\n",
    "def get_val_transforms():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])"
   ],
   "metadata": {
    "id": "transforms"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Dataset with class-aware augmentation\n",
    "class BalancedSkinDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None, malignant_transform=None, is_training=True):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.malignant_transform = malignant_transform\n",
    "        self.is_training = is_training\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        if self.is_training and label == 1 and self.malignant_transform:\n",
    "            img = self.malignant_transform(img)\n",
    "        elif self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ],
   "metadata": {
    "id": "dataset"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "def load_data(data_dir):\n",
    "    data_path = Path(data_dir)\n",
    "    image_paths, labels = [], []\n",
    "\n",
    "    for img in (data_path / 'benign').glob('*.jpg'):\n",
    "        image_paths.append(str(img))\n",
    "        labels.append(0)\n",
    "    for img in (data_path / 'malignant').glob('*.jpg'):\n",
    "        image_paths.append(str(img))\n",
    "        labels.append(1)\n",
    "\n",
    "    print(f\"Loaded {len(image_paths)} images\")\n",
    "    print(f\"  Benign: {labels.count(0)}, Malignant: {labels.count(1)}\")\n",
    "    return image_paths, labels\n",
    "\n",
    "# Create weighted sampler\n",
    "def create_weighted_sampler(labels):\n",
    "    counter = Counter(labels)\n",
    "    weights = {c: 1.0/n for c, n in counter.items()}\n",
    "    sample_weights = [weights[l] for l in labels]\n",
    "    return WeightedRandomSampler(sample_weights, len(labels), replacement=True)\n",
    "\n",
    "# Compute class weights\n",
    "def compute_class_weights(labels, device):\n",
    "    counter = Counter(labels)\n",
    "    total = len(labels)\n",
    "    weights = torch.tensor([\n",
    "        total / counter[0],\n",
    "        (total / counter[1]) * 2.0  # Extra weight for malignant\n",
    "    ], dtype=torch.float32)\n",
    "    weights = weights / weights.sum() * 2\n",
    "    print(f\"Class weights: Benign={weights[0]:.3f}, Malignant={weights[1]:.3f}\")\n",
    "    return weights.to(device)"
   ],
   "metadata": {
    "id": "data-loading"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Model\n",
    "def create_model(num_classes=2, pretrained=True, dropout=0.3):\n",
    "    model = models.resnet50(weights='IMAGENET1K_V2' if pretrained else None)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(num_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "    return model"
   ],
   "metadata": {
    "id": "model"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Training functions\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "    for images, labels in tqdm(loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    return running_loss / len(loader), 100. * correct / total\n",
    "\n",
    "def evaluate(model, loader, criterion, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_labels, all_preds, all_probs = [], [], []\n",
    "    running_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Evaluating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "            preds = (probs[:, 1] >= threshold).long()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    metrics = {\n",
    "        'loss': running_loss / len(loader),\n",
    "        'accuracy': (tp + tn) / (tp + tn + fp + fn) * 100,\n",
    "        'sensitivity': tp / (tp + fn) * 100 if (tp + fn) > 0 else 0,\n",
    "        'specificity': tn / (tn + fp) * 100 if (tn + fp) > 0 else 0,\n",
    "        'precision': tp / (tp + fp) * 100 if (tp + fp) > 0 else 0,\n",
    "        'f1': 2*tp / (2*tp + fp + fn) * 100 if (2*tp + fp + fn) > 0 else 0,\n",
    "        'auc': roc_auc_score(all_labels, all_probs) * 100 if len(np.unique(all_labels)) > 1 else 0,\n",
    "        'tp': tp, 'tn': tn, 'fp': fp, 'fn': fn\n",
    "    }\n",
    "    return metrics, all_labels, all_probs"
   ],
   "metadata": {
    "id": "training-funcs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Configuration\nCONFIG = {\n    'data_dir': '/content/drive/MyDrive/DermAI_Training/organized',  # Direct from Google Drive\n    'output_dir': '/content/drive/MyDrive/DermAI_Training/checkpoints',\n    'epochs': 8,\n    'batch_size': 32,\n    'lr': 1e-4,\n    'use_focal_loss': True,\n    'focal_gamma': 2.0,\n    'target_sensitivity': 0.90,\n}\n\nprint(\"Training Configuration:\")\nfor k, v in CONFIG.items():\n    print(f\"  {k}: {v}\")",
   "metadata": {
    "id": "run-header"
   }
  },
  {
   "cell_type": "code",
   "source": "# Configuration\nCONFIG = {\n    'data_dir': '/content/data/organized',  # Local copy for faster training\n    'output_dir': '/content/drive/MyDrive/DermAI_Training/checkpoints',\n    'epochs': 8,\n    'batch_size': 32,\n    'lr': 1e-4,\n    'use_focal_loss': True,\n    'focal_gamma': 2.0,\n    'target_sensitivity': 0.90,\n}\n\nprint(\"Training Configuration:\")\nfor k, v in CONFIG.items():\n    print(f\"  {k}: {v}\")",
   "metadata": {
    "id": "config"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load and split data\n",
    "image_paths, labels = load_data(CONFIG['data_dir'])\n",
    "\n",
    "train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.3, stratify=labels, random_state=42\n",
    ")\n",
    "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
    "    temp_paths, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain: {len(train_paths)} | Val: {len(val_paths)} | Test: {len(test_paths)}\")"
   ],
   "metadata": {
    "id": "load-data"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create datasets and loaders\n",
    "train_dataset = BalancedSkinDataset(\n",
    "    train_paths, train_labels,\n",
    "    transform=get_train_transforms(False),\n",
    "    malignant_transform=get_train_transforms(True),\n",
    "    is_training=True\n",
    ")\n",
    "val_dataset = BalancedSkinDataset(val_paths, val_labels, transform=get_val_transforms(), is_training=False)\n",
    "test_dataset = BalancedSkinDataset(test_paths, test_labels, transform=get_val_transforms(), is_training=False)\n",
    "\n",
    "train_sampler = create_weighted_sampler(train_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], sampler=train_sampler, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)} | Val batches: {len(val_loader)} | Test batches: {len(test_loader)}\")"
   ],
   "metadata": {
    "id": "create-loaders"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create model, loss, optimizer\n",
    "model = create_model().to(device)\n",
    "class_weights = compute_class_weights(train_labels, device)\n",
    "\n",
    "if CONFIG['use_focal_loss']:\n",
    "    criterion = FocalLoss(alpha=class_weights, gamma=CONFIG['focal_gamma'])\n",
    "    print(\"Using Focal Loss\")\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    print(\"Using Weighted Cross Entropy\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG['lr'], weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG['epochs'])"
   ],
   "metadata": {
    "id": "create-model"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Training loop with RESUME support\nhistory = {'train_loss': [], 'val_loss': [], 'val_sensitivity': [], 'val_specificity': [], 'val_auc': []}\nbest_sensitivity = 0\nstart_epoch = 0\n\nbest_model_path = Path(CONFIG['output_dir']) / 'best_balanced_model.pth'\nlatest_checkpoint_path = Path(CONFIG['output_dir']) / 'latest_checkpoint.pth'\n\n# ========== RESUME FROM CHECKPOINT ==========\nif latest_checkpoint_path.exists():\n    print(\"Found existing checkpoint! Loading...\")\n    checkpoint = torch.load(latest_checkpoint_path)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n    start_epoch = checkpoint['epoch'] + 1\n    best_sensitivity = checkpoint['best_sensitivity']\n    history = checkpoint['history']\n    print(f\"Resuming from epoch {start_epoch + 1}\")\n    print(f\"Best sensitivity so far: {best_sensitivity:.1f}%\")\nelse:\n    print(\"No checkpoint found. Starting fresh training.\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING WITH CLASS BALANCING\")\nprint(f\"Target: {CONFIG['target_sensitivity']*100:.0f}% sensitivity\")\nif start_epoch > 0:\n    print(f\"RESUMING FROM EPOCH {start_epoch + 1}\")\nprint(\"=\"*60 + \"\\n\")\n\nfor epoch in range(start_epoch, CONFIG['epochs']):\n    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n    val_metrics, _, _ = evaluate(model, val_loader, criterion, device)\n    scheduler.step()\n\n    history['train_loss'].append(train_loss)\n    history['val_loss'].append(val_metrics['loss'])\n    history['val_sensitivity'].append(val_metrics['sensitivity'])\n    history['val_specificity'].append(val_metrics['specificity'])\n    history['val_auc'].append(val_metrics['auc'])\n\n    print(f\"\\nEpoch {epoch+1}/{CONFIG['epochs']}:\")\n    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.1f}%\")\n    print(f\"  Val Sensitivity: {val_metrics['sensitivity']:.1f}% | Specificity: {val_metrics['specificity']:.1f}%\")\n    print(f\"  Val AUC: {val_metrics['auc']:.1f}% | F1: {val_metrics['f1']:.1f}%\")\n\n    # Save best model (based on sensitivity)\n    if val_metrics['sensitivity'] > best_sensitivity:\n        best_sensitivity = val_metrics['sensitivity']\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'metrics': val_metrics,\n        }, best_model_path)\n        print(f\"  * New best model saved! (Sensitivity: {best_sensitivity:.1f}%)\")\n\n    # Save latest checkpoint for resume (EVERY epoch)\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'scheduler_state_dict': scheduler.state_dict(),\n        'best_sensitivity': best_sensitivity,\n        'history': history,\n        'val_metrics': val_metrics,\n    }, latest_checkpoint_path)\n    print(f\"  Checkpoint saved (can resume if disconnected)\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING COMPLETE!\")\nprint(f\"Best sensitivity achieved: {best_sensitivity:.1f}%\")\nprint(\"=\"*60)",
   "metadata": {
    "id": "train-loop"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5: Final Evaluation"
   ],
   "metadata": {
    "id": "eval-header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Load best model and evaluate on test set\n",
    "checkpoint = torch.load(best_model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "\n",
    "test_metrics, test_labels_arr, test_probs = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL TEST RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy: {test_metrics['accuracy']:.1f}%\")\n",
    "print(f\"Sensitivity (Recall): {test_metrics['sensitivity']:.1f}%  <- Catches {test_metrics['sensitivity']:.0f}% of cancers\")\n",
    "print(f\"Specificity: {test_metrics['specificity']:.1f}%\")\n",
    "print(f\"Precision: {test_metrics['precision']:.1f}%\")\n",
    "print(f\"F1 Score: {test_metrics['f1']:.1f}%\")\n",
    "print(f\"AUC-ROC: {test_metrics['auc']:.1f}%\")\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"  TP={test_metrics['tp']} (cancers caught)\")\n",
    "print(f\"  FN={test_metrics['fn']} (cancers missed)\")\n",
    "print(f\"  TN={test_metrics['tn']} (benign correct)\")\n",
    "print(f\"  FP={test_metrics['fp']} (false alarms)\")"
   ],
   "metadata": {
    "id": "final-eval"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(history['train_loss'], label='Train')\n",
    "axes[0].plot(history['val_loss'], label='Val')\n",
    "axes[0].set_title('Loss')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(history['val_sensitivity'], label='Sensitivity', color='red')\n",
    "axes[1].plot(history['val_specificity'], label='Specificity', color='blue')\n",
    "axes[1].axhline(y=90, color='green', linestyle='--', label='90% Target')\n",
    "axes[1].set_title('Sensitivity vs Specificity')\n",
    "axes[1].set_ylim([0, 100])\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].plot(history['val_auc'], label='AUC', color='purple')\n",
    "axes[2].set_title('AUC-ROC')\n",
    "axes[2].set_ylim([50, 100])\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CONFIG['output_dir']}/training_curves.png\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "plot-history"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Save results\n",
    "results = {\n",
    "    'config': CONFIG,\n",
    "    'test_metrics': test_metrics,\n",
    "    'history': history,\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "}\n",
    "\n",
    "with open(f\"{CONFIG['output_dir']}/training_results.json\", 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to {CONFIG['output_dir']}\")\n",
    "print(f\"\\nTo use this model in DermAI Pro:\")\n",
    "print(f\"1. Download: {best_model_path}\")\n",
    "print(f\"2. Copy to: backend/checkpoints/balanced/best_balanced_model.pth\")"
   ],
   "metadata": {
    "id": "save-results"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Done!\n",
    "\n",
    "Your balanced model is saved to Google Drive. Download and use it in your DermAI Pro backend.\n",
    "\n",
    "**Expected improvement:**\n",
    "- Before: 30% precision, 41% recall for malignant\n",
    "- After: 60-75% precision, **85-95% recall** for malignant"
   ],
   "metadata": {
    "id": "done"
   }
  }
 ]
}